debug: false
seed: 42
run:
  name: "train_unet_${now:%Y-%m-%d_%H-%M-%S}"
model:
  number_of_input_channels: 16
  number_of_classes: 1
  activation_fn_name: "relu"
  num_encoder_decoder_blocks: 4
  use_batchnorm: true
  optimizer:
    name: "adam"
    lr: 0.0001
output_path: "data/trainings/"
data:
  split_info_file_path: 'data/splits/holdout_split_2010_2023_2024-08-24_14-45-41/data_split_info.json'
  destination_no_data_value: -32768.0
  data_loading_num_workers: 6
  input_data_indexes_to_remove: []
training:
  max_nb_epochs: 100
  train_batch_size: 16
  eval_batch_size: 32
  optimization_metric_name: "dice_loss"
  minimize_optimization_metric: true
  data_augs:
    - name: "RandomVerticalFlip"
      params:
        p: 0.5
    - name: "RandomHorizontalFlip"
      params:
        p: 0.5
    - name: "RandomRotate"
      params:
        p: 0.5
        degrees: 35
  loss:
    name: "dice_loss"
    params:
      mode: "binary"
      log_loss: false
      from_logits: true
logging:
  loggers:
    # - loguru
    - cometml