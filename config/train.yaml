debug: false
seed: 42
run:
  name: "train_unet_${now:%Y-%m-%d_%H-%M-%S}"
model:
  number_of_input_channels: 16
  number_of_classes: 1
  activation_fn_name: "relu"
  num_encoder_decoder_blocks: 4
  use_batchnorm: true
  optimizer:
    name: "adam"
    params:
      lr : 0.001
      weight_decay: 0.0001
  lr_scheduler:
    name: "cosine_annealing_lr"
    params:
      T_max: 50
output_path: "data/trainings/"
data:
  split_info_file_path: 'data/splits/holdout_split_2010_2023_2024-08-24_14-45-41/data_split_info.json'
  destination_no_data_value: 0.0
  data_loading_num_workers: 6
  input_data_indexes_to_remove: []
training:
  max_nb_epochs: 50
  train_batch_size: 16
  eval_batch_size: 32
  optimization_metric_name: "ce_loss"
  minimize_optimization_metric: true
  data_augs:
    - name: "RandomVerticalFlip"
      params:
        p: 0.5
    - name: "RandomHorizontalFlip"
      params:
        p: 0.5
  loss:
    name: "dice_loss"
    params:
      smooth: 1e-5
      from_logits: true
logging:
  metrics:
    - name: "dice_loss"
      params:
        smooth: 1e-5
        from_logits: true
    - name: "ce_loss"
      params: {}
    - name: "pr_auc"
      params: {}
  loggers:
    # - loguru
    - cometml